ğŸ“˜ **DBMS Assignment**
*A complete guide to PF Layer Buffering, Slotted Pages, and Index Construction in ToyDB*

---

# ğŸ›ï¸ **Introduction**

This project extends the **ToyDB** systemâ€”an educational database that consists of:

1. **PF Layer (Paged File Layer)**  
   Manages fixed-size disk pages, buffering, and low-level storage.

2. **AM Layer (Access Method Layer)**  
   Implements B+ treeâ€“based indexing on top of PF.

3. **Higher-level modules**  
   Including a **slotted-page structure** to store variable-length student records.

The assignment required implementing three major objectives:

- **Objective 1:**  
  PF Layer page buffering with LRU/MRU replacement, I/O statistics, and graph generation for real database workloads.

- **Objective 2:**  
  A variable-length record **slotted-page** storage engine and its performance evaluation.

- **Objective 3:**  
  Comparison of three different **B+ tree index construction methods** in the AM Layer.

This README explains all implementations, how to run them, and the complete performance results.

---

# ğŸ”¥ **Objective 1 â€“ PF Layer Buffering, LRU/MRU & Real-Data Graphs**

## ğŸ¯ Goal
Implement a full buffer manager inside the PF layer with:

- **Two replacement strategies:**  
  - **LRU (default)**  
  - **MRU (useful for sequential workloads)**

- **Configurable buffer pool size**
- **Dirty-bit management**
- **Logical vs physical I/O counters**
- **Support for 11 read/write mixtures (100/0 â†’ 0/100)**
- **Graph generation using real database files**
- **CSV statistics export**

All results must visualize:
> **X-axis â†’ read/write mixture**  
> **Y-axis â†’ hit ratio / buffer stats / physical I/O**

---

## ğŸ“ Relevant Files

pflayer/
â”œâ”€â”€ test_realdata.c # Generates statistics & CSV output
â”œâ”€â”€ generate_graphs.py # Creates professional graphs
â”œâ”€â”€ Makefile # Automates tests & graph creation
â”œâ”€â”€ realdata_lru.csv # Generated statistics
â”œâ”€â”€ realdata_mru.csv # Generated statistics
â””â”€â”€ graphs/ # Output graphs

---

## ğŸ§ª Running the Tests

### Generate all results + graphs
```bash
make graphs
```

Clean only generated results
```bash
make clean-results
```

Full rebuild
```bash
make clean
make tests
make graphs
```

ğŸ“Š Real Dataset Used

| File           | Approx. Pages | Description           |
|----------------|--------------|----------------------|
| student.txt    | 446 pages    | Large dataset (~17K rows) |
| courses.txt    | 107 pages    | Medium dataset       |
| studemail.txt  | 133 pages    | Medium dataset       |
| department.txt | 10 pages     | Very small dataset   |
| program.txt    | 10 pages     | Very small dataset   |

Each workload runs 5000 operations with random page accesses.

ğŸ“ˆ Generated CSV Files

- realdata_lru.csv
- realdata_mru.csv

Format:

Dataset,ReadPct,WritePct,NumPages,  
LogicalReads,LogicalWrites,  
PhysicalReads,PhysicalWrites,  
BufferHits,BufferMisses,HitRatio

ğŸ–¼ï¸ Graphs Generated

- hit_ratio_vs_mixture.png  
  Primary graph: Shows LRU vs MRU for each workload

- physical_io_vs_mixture.png  
  Tracks actual disk I/O

- strategy_comparison.png  
  Side-by-side summary: hit ratios + total I/O

- buffer_performance.png  
  Bar chart of hits/misses for each mixture

All graphs are placed in graphs/.

ğŸ“Œ Key Results

**Small Datasets (<20 pages)**
- Hit ratio ~ 99.8%
- All pages fit in memory â†’ replacement strategy irrelevant

**Medium Datasets (100â€“150 pages)**
- LRU â‰ˆ MRU
- Hit ratio ~ 15%â€“19%

**Large Dataset (446 pages)**
- Hit ratio ~ 4â€“5%
- Both LRU and MRU struggle due to random workload + limited buffer

**Main Insights**
- Strategy differences appear only in hotspot workloads
- Random workloads minimize LRU/MRU differences
- Buffer size relative to dataset size is the dominating factor

---

# ğŸ§© Objective 2 â€“ Slotted Page Implementation for Variable-Length Records

## ğŸ¯ Goal

Design a slotted-page structure capable of storing variable-length student records, supporting:

- Page initialization
- Record insertion
- Record deletion
- Sequential scanning
- Automatic page compaction
- File-level record management
- Space utilization analysis vs fixed-size storage

## ğŸ—‚ï¸ File Structure

objective2/
â”‚â”€â”€ slotted_page.c/h
â”‚â”€â”€ student_file.c/h
â”‚â”€â”€ test_objective2_final.c
â”‚â”€â”€ run_objective2_tests.sh
â”‚â”€â”€ IMPLEMENTATION_GUIDE_OBJ2.md
â””â”€â”€ Makefile

## ğŸ§  How Slotted Pages Work

A 4KB page contains:

- 32-byte page header:  
  free space pointer, slot count, total used bytes

- Slot directory (grows downward)
- Record area (grows upward)

On deletion:

- Slot marked dead
- compact_page() removes fragmentation and repacks records

## ğŸ§ª Running Tests

Build:
```bash
make
```

Full test (10,000 records):
```bash
make test
```

Quick test (1,000 records):
```bash
make test-quick
```

Custom size:
```bash
./test_objective2_final 5000
```

## ğŸ“Š Performance Comparison

| Method         | File Size | Utilization | Avg Record Size | Space Savings |
|----------------|-----------|-------------|-----------------|--------------|
| Slotted Page   | ~1 MB     | 94%         | 97 bytes        | Baseline     |
| Static 256B    | ~2.5 MB   | 100%        | 256B            | -60%         |
| Static 512B    | ~5 MB     | 100%        | 512B            | -80%         |
| Static 1024B   | ~10 MB    | 100%        | 1024B           | -90%         |

**Summary**
- Slotted pages save 60â€“90% space
- Minimal overhead compared to fixed-size storage
- Highly efficient for real datasets with variable-length text fields

---

# ğŸŒ³ Objective 3 â€“ B+ Tree Index Construction (Three Methods)

## ğŸ¯ Goal

Implement and compare three index-building strategies inside the AM layer:

- Method 1: Bulk Creation  
  Build index on an existing unsorted data file.

- Method 2: Incremental Insertion  
  Build index as records arrive (simulate OLTP).

- Method 3: Bulk-Loading using Pre-sorted Data  
  Sort file by key â†’ build index sequentially.

## ğŸ“ File Location

toydb/amlayer/
â”‚â”€â”€ test_objective3.c
â”‚â”€â”€ misc.c
â”‚â”€â”€ am.c, aminsert.c, amsearch.c, amfns.c
â”‚â”€â”€ makefile
â””â”€â”€ Uses ../pflayer/ and ../../../data/student.txt

## âš™ï¸ Running Tests

Build:
```bash
make test_objective3
```

Run:
```bash
./test_objective3 1000
./test_objective3 17815
```

Clean:
```bash
make clean
```

## ğŸ“Š Performance Summary (17,815 records)

| Method                | Time (sec) | Rate (rec/s) | Notes         |
|-----------------------|------------|--------------|---------------|
| 1: Bulk Build         | 0.016      | 1.11M        | Baseline      |
| 2: Incremental Insert | 0.016      | 1.12M        | Often fastest |
| 3: Bulk-Loading       | 0.019      | 0.94M        | Sorting dominates |

**Interpretation**
- For ~17K records:  
  Sorting cost outweighs the structural benefits â†’ Bulk-loading appears slower.
- For 100K+ records:  
  Bulk-loading becomes significantly faster than random insertions.

**Output Files Created**
- student_method1.0
- student_method2.0
- student_method3.0

Each file is a fully constructed B+ tree index.

---

# ğŸ§  Overall Takeaways

**PF Layer**
- Fully functional buffer manager
- LRU & MRU with real-world workloads
- Statistical analysis + graph generation

**Slotted Pages**
- Highly space-efficient
- Supports insert, delete, scan, compaction
- Ideal for variable-length data

**AM Layer**
- Three index construction strategies
- Full comparison using real student dataset
- Proper integration with ToyDB's AM APIs

---

# âš™ï¸ Build Instructions Summary

| Component    | Build                      | Run                       | Clean             |
|--------------|---------------------------|---------------------------|-------------------|
| Objective 1  | make tests / make graphs   | ./test_realdata           | make clean-results|
| Objective 2  | make                      | make test                 | make clean-all    |
| Objective 3  | make test_objective3       | ./test_objective3 <N>     | make clean        |

---

# ğŸ“¦ Repository Structure

project/
â”œâ”€â”€ pflayer/              # Objective 1
â”œâ”€â”€ objective2/           # Objective 2
â”œâ”€â”€ amlayer/              # Objective 3
â”œâ”€â”€ data/                 # Provided student datasets
â””â”€â”€ README.md             # Combined project documentation
